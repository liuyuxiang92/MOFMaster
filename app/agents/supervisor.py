import logging
import json
import re
from langchain_core.messages import SystemMessage

from app.state import AgentState
from app.schema import SupervisorReview
from app.utils.llm import get_supervisor_llm

# Setup logger
logger = logging.getLogger(__name__)


SUPERVISOR_SYSTEM_PROMPT = """You are a Principal Investigator (PI) reviewing a computational chemistry workflow plan for the MOF-Scientist backend.

Your job is to ensure the plan is:
1. SCIENTIFICALLY SOUND ‚Äì Operations follow good computational chemistry practice and the knowledge base.
2. FEASIBLE ‚Äì Only uses available tools with valid inputs.
3. SAFE ‚Äì Avoids obviously wasteful or redundant computations.
4. RELEVANT ‚Äì Directly addresses the user's request and scientific goals.

SCIENTIFIC RULES (derived from the knowledge base):
- Structure acquisition (`search_mofs` or user-provided CIF) must happen before any operations that require a structure.
- Geometry optimization (`optimize_structure`) should typically precede energy/force calculations for meaningful results, unless the user explicitly wants a quick, non-optimized estimate.
- Energy calculations (`calculate_energy`) are appropriate when the user asks about energy, stability, or forces, or when they implicitly want "stability" comparisons.
- If the user explicitly states they only want search or optimization (and *no* energies), additional energy steps should be rejected.

AVAILABLE TOOLS (you are only reviewing their ordering and necessity):
- search_mofs: Search for MOF structures.
- optimize_structure: Optimize geometry.
- calculate_energy: Calculate energy and forces.

{revision_context}

USER REQUEST:
{user_query}

REVIEW THE PLAN (sequence of tool names):
{plan}

IMPORTANT: You must respond with valid JSON only. The response will be parsed as JSON.
Provide your review as a JSON object with:
- "approved": true or false (boolean)
- "feedback": "Detailed explanation" (string)

If approved, explain briefly why the plan is good (e.g., correct order, sufficient but not excessive steps).
If rejected, be specific about:
- Which steps are missing, out of order, unnecessary, or conflicting with the user's explicit instructions.
- How to fix or improve the plan according to the knowledge base.
{revision_instructions}
"""


async def supervisor_node(state: AgentState) -> AgentState:
    """
    Supervisor Agent - Reviews the plan for scientific soundness.

    Uses an LLM to validate the execution plan generated by the Analyzer.
    Checks order of operations, feasibility, and safety.
    """

    # Get the latest plan from state - ensure we're reading the current state
    plan = state.get("plan", [])
    
    # Debug: Print what plan the supervisor is seeing
    logger.debug(f"üîç Supervisor: Received plan from state: {plan}")
    logger.debug(f"üîç Supervisor: Plan type: {type(plan)}, Plan length: {len(plan) if plan else 0}")
    logger.debug(f"üîç Supervisor: Full state keys: {list(state.keys())}")

    if not plan:
        # No plan to review, skip
        logger.warning("‚ö†Ô∏è  Supervisor: No plan found in state!")
        state["is_plan_approved"] = False
        state["review_feedback"] = "No plan provided"
        return state

    # Check if this is a revised plan
    rejection_count = state.get("_rejection_count", 0)
    previous_plan = state.get("_previous_plan", [])
    previous_feedback = state.get("review_feedback", "")
    
    logger.debug(f"üîç Supervisor: rejection_count={rejection_count}")
    logger.debug(f"üîç Supervisor: previous_plan={previous_plan} (length={len(previous_plan) if previous_plan else 0})")
    logger.debug(f"üîç Supervisor: current_plan={plan} (length={len(plan)})")
    logger.debug(f"üîç Supervisor: previous_feedback={previous_feedback[:100] if previous_feedback else 'None'}...")
    
    # Verify we have the latest plan - compare with previous if available
    if previous_plan and plan == previous_plan:
        logger.warning(f"‚ö†Ô∏è  WARNING: Current plan is identical to previous plan! This might indicate a state update issue.")
    elif previous_plan:
        logger.info(f"‚úÖ Plan has changed from previous version")
    
    # Build revision context if this is a revision
    if rejection_count > 0 and previous_plan:
        revision_context = f"""
‚ö†Ô∏è  REVISED PLAN - This is revision #{rejection_count + 1}

PREVIOUS PLAN (that was rejected):
{chr(10).join(f"{i+1}. {step}" for i, step in enumerate(previous_plan))}

YOUR PREVIOUS FEEDBACK:
{previous_feedback}

CURRENT REVISED PLAN (to review):
"""
        revision_instructions = """

IMPORTANT FOR REVISIONS:
- Compare the revised plan with the previous plan and your feedback
- Check if the revisions address your previous concerns
- If the plan has improved based on your feedback, consider approving it
- If the plan still has the same issues or new problems, provide specific feedback on what still needs to be fixed
"""
    else:
        revision_context = ""
        revision_instructions = ""

    # Create review prompt
    llm = get_supervisor_llm()

    # Use structured output with JSON mode
    # Try to use response_format if available (OpenAI JSON mode)
    try:
        # For OpenAI-compatible APIs, try to enable JSON mode
        if hasattr(llm, 'bind'):
            # Try binding response_format for JSON mode
            structured_llm = llm.bind(response_format={"type": "json_object"}).with_structured_output(SupervisorReview)
        else:
            structured_llm = llm.with_structured_output(SupervisorReview)
    except Exception:
        # Fallback to standard structured output
        structured_llm = llm.with_structured_output(SupervisorReview)

    system_message = SystemMessage(
        content=SUPERVISOR_SYSTEM_PROMPT.format(
            revision_context=revision_context,
            user_query=state.get("original_query", "No query provided"),
            plan="\n".join(f"{i+1}. {step}" for i, step in enumerate(plan)),
            revision_instructions=revision_instructions
        )
    )

    # Get review
    try:
        review = await structured_llm.ainvoke([system_message])
        logger.info(f"‚úÖ Supervisor review: approved={review.approved}, feedback={review.feedback[:100]}...")
    except Exception as e:
        # If structured output fails, fall back to manual parsing
        logger.warning(f"‚ö†Ô∏è  Structured output failed, attempting fallback: {e}")
        try:
            response = await llm.ainvoke([system_message])
            content = response.content if hasattr(response, 'content') else str(response)
            logger.debug(f"üìù Raw supervisor response: {content[:300]}...")
            
            # Try to parse JSON from response
            import json
            import re
            # Look for JSON object with approved field
            json_match = re.search(r'\{[^{}]*"approved"[^{}]*\}', content, re.DOTALL)
            if not json_match:
                # Try to find any JSON object
                json_match = re.search(r'\{.*?"approved".*?\}', content, re.DOTALL)
            
            if json_match:
                try:
                    parsed = json.loads(json_match.group(0))
                    review = SupervisorReview(
                        approved=parsed.get("approved", False),
                        feedback=parsed.get("feedback", content[:500])
                    )
                    logger.info(f"‚úÖ Parsed review from fallback: approved={review.approved}")
                except json.JSONDecodeError as je:
                    logger.error(f"‚ùå JSON decode error: {je}")
                    # Last resort: be lenient and approve if plan looks reasonable
                    review = SupervisorReview(
                        approved=len(plan) > 0,  # Approve if we have a plan
                        feedback=f"Could not parse review. Auto-approving reasonable plan. Error: {str(je)[:100]}"
                    )
            else:
                # No JSON found, be lenient - approve if plan exists and looks reasonable
                logger.warning(f"‚ö†Ô∏è  No JSON found in response. Plan length: {len(plan)}")
                review = SupervisorReview(
                    approved=len(plan) > 0,  # Approve if we have a plan
                    feedback=f"Could not parse JSON from response. Auto-approving plan. Response preview: {content[:200]}"
                )
        except Exception as fallback_error:
            logger.error(f"‚ùå Fallback parsing also failed: {fallback_error}")
            # Last resort: approve if plan exists
            review = SupervisorReview(
                approved=len(plan) > 0,
                feedback=f"Error getting supervisor review: {str(fallback_error)[:200]}. Auto-approving plan."
            )

    # Update state
    state["is_plan_approved"] = review.approved
    state["review_feedback"] = review.feedback
    
    # Track rejection count to prevent infinite loops
    if not review.approved:
        rejection_count = state.get("_rejection_count", 0)
        rejection_count += 1
        state["_rejection_count"] = rejection_count
        
        # Auto-approve after 3 rejections to prevent infinite loop
        if rejection_count >= 3:
            logger.warning(f"‚ö†Ô∏è  Auto-approving plan after {rejection_count} rejections to prevent infinite loop")
            state["is_plan_approved"] = True
            state["review_feedback"] = f"Auto-approved after {rejection_count} rejections. Previous feedback: {review.feedback}"
    else:
        # Reset rejection count and clear previous plan on approval
        state["_rejection_count"] = 0
        state["_previous_plan"] = []

    return state
